{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysf-s/Hi-Paris-AI-Data-Science-Hackathon-Group-42-/blob/main/Prediction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUaydstgqHdr",
        "outputId": "eced4601-2183-468e-be25-c0d8da6b17c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_54Sfkl2u2B"
      },
      "source": [
        "# PISA Math Score Prediction Pipeline\n",
        "\n",
        "This notebook builds a two-stage model (classifier + regressor) to predict math scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3b_dBAL2u2F"
      },
      "source": [
        "## 1. Load Data and Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHEw6vpWUMqy",
        "outputId": "7ee05274-550b-48ea-ded3-eee6dfaa7576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1172086, 307)\n",
            "X_test shape: (586044, 307)\n",
            "y_train shape: (1172086, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Copy of y_train.csv')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Copy of X_train.csv')\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Copy of X_test.csv')\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH1ByR0qwPcr",
        "outputId": "50467442-a319-43ee-d690-6a365ec33da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl.metadata (2.1 kB)\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-3.1.2-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl (289.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost, lightgbm\n",
            "Successfully installed lightgbm-4.6.0 nvidia-nccl-cu12-2.29.2 xgboost-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWjTvu_32u2J"
      },
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4v014F42u2K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, r2_score\n",
        "import re\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jitpiZrh2u2M"
      },
      "source": [
        "## 3. Feature Engineering Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0tnxogI2u2N"
      },
      "outputs": [],
      "source": [
        "def engineer_psychometrics(df):\n",
        "    \"\"\"Create psychometric indicator features.\"\"\"\n",
        "    df = df.copy()\n",
        "    if 'MATHEASE' in df.columns:\n",
        "        df['has_math_attitude'] = df['MATHEASE'].notna().astype(int)\n",
        "    if 'ST290' in df.columns:\n",
        "        df['math_confidence_present'] = df['ST290'].notna().astype(int)\n",
        "    if 'ST213' in df.columns:\n",
        "        df['teacher_feedback_present'] = df['ST213'].notna().astype(int)\n",
        "    if 'ST296' in df.columns:\n",
        "        try:\n",
        "            df['does_homework'] = (pd.to_numeric(df['ST296'], errors='coerce') > 0).astype(int)\n",
        "        except:\n",
        "            pass\n",
        "    return df\n",
        "\n",
        "def engineer_features(df):\n",
        "    \"\"\"Create timing, effort, and clustering features.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Starting indicator\n",
        "    if 'math_q1_total_timing' in df.columns:\n",
        "        df['started_math'] = df['math_q1_total_timing'].notna().astype(int)\n",
        "\n",
        "    # Timing features\n",
        "    sci_cols = [c for c in df.columns if 'science_q' in c and 'total_timing' in c]\n",
        "    read_cols = [c for c in df.columns if 'reading_q' in c and 'total_timing' in c]\n",
        "\n",
        "    df['total_sci_time'] = df[sci_cols].fillna(0).sum(axis=1)\n",
        "    df['total_read_time'] = df[read_cols].fillna(0).sum(axis=1)\n",
        "    df['total_global_time'] = df['total_sci_time'] + df['total_read_time']\n",
        "    df['n_items_attempted'] = df[sci_cols + read_cols].notna().sum(axis=1)\n",
        "    df['std_response_time'] = df[sci_cols + read_cols].std(axis=1).fillna(-1)\n",
        "\n",
        "    # Student persona clustering\n",
        "    cluster_cols = ['total_global_time', 'n_items_attempted', 'std_response_time']\n",
        "    X_cluster = df[cluster_cols].fillna(0)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_cluster)\n",
        "    kmeans = KMeans(n_clusters=7, random_state=42, n_init=10)\n",
        "    df['student_persona'] = kmeans.fit_predict(X_scaled).astype(int)\n",
        "\n",
        "    # Wealth index\n",
        "    possessions = [c for c in df.columns if c.startswith('ST25')]\n",
        "    df['wealth_index'] = df[possessions].notna().sum(axis=1)\n",
        "\n",
        "    # Effort interactions\n",
        "    if 'EFFORT1' in df.columns:\n",
        "        df['EFFORT1_clean'] = pd.to_numeric(df['EFFORT1'], errors='coerce').fillna(0)\n",
        "        df['wealth_x_effort'] = df['wealth_index'] * df['EFFORT1_clean']\n",
        "        df['time_x_effort'] = df['total_global_time'] * df['EFFORT1_clean']\n",
        "\n",
        "    return df\n",
        "\n",
        "def sanitize_cols(df):\n",
        "    \"\"\"Sanitize column names for XGBoost compatibility.\"\"\"\n",
        "    new_cols = [re.sub(r'[^a-zA-Z0-9_]', '_', str(c)) for c in df.columns]\n",
        "    df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "def smoothed_target_encoding(train_df, test_df, target, cat_col, alpha=5):\n",
        "    \"\"\"Apply smoothed target encoding to categorical features.\"\"\"\n",
        "    global_mean = target.mean()\n",
        "    agg = train_df.groupby(cat_col)[target.name].agg(['count', 'sum'])\n",
        "    smoothed = (agg['sum'] + (alpha * global_mean)) / (agg['count'] + alpha)\n",
        "\n",
        "    train_df[f'TE_{cat_col}'] = train_df[cat_col].map(smoothed).astype(float).fillna(global_mean)\n",
        "    test_df[f'TE_{cat_col}'] = test_df[cat_col].map(smoothed).astype(float).fillna(global_mean)\n",
        "    return train_df, test_df\n",
        "\n",
        "def process_year_data(X_train, y_train, X_test):\n",
        "    \"\"\"Process data for a specific year: target encoding, feature creation, and column alignment.\"\"\"\n",
        "    X_train = X_train.copy()\n",
        "    X_test = X_test.copy()\n",
        "\n",
        "    temp_train = X_train.copy()\n",
        "    temp_train['target'] = y_train\n",
        "\n",
        "    # Apply target encodings\n",
        "    X_train, X_test = smoothed_target_encoding(temp_train, X_test, temp_train['target'], 'CNTSCHID', alpha=5)\n",
        "    X_train, X_test = smoothed_target_encoding(temp_train, X_test, temp_train['target'], 'student_persona', alpha=50)\n",
        "    if 'MATHEASE' in X_train.columns:\n",
        "        X_train, X_test = smoothed_target_encoding(temp_train, X_test, temp_train['target'], 'MATHEASE', alpha=50)\n",
        "\n",
        "    # Create interaction features\n",
        "    if 'EFFORT1_clean' in X_train.columns:\n",
        "        X_train['School_x_Effort'] = X_train['TE_CNTSCHID'] * X_train['EFFORT1_clean']\n",
        "        X_test['School_x_Effort'] = X_test['TE_CNTSCHID'] * X_test['EFFORT1_clean']\n",
        "\n",
        "    # Drop raw categorical columns\n",
        "    cols_to_drop = ['CNTSCHID', 'CNT', 'STRATUM', 'OCOD1', 'OCOD2', 'student_persona', 'MATHEASE', 'ST290']\n",
        "    X_train = X_train.drop(columns=cols_to_drop, errors='ignore')\n",
        "    X_test = X_test.drop(columns=cols_to_ban, errors='ignore')\n",
        "\n",
        "    # Align columns\n",
        "    common_cols = [c for c in X_train.columns if c in X_test.columns]\n",
        "    X_train = sanitize_cols(X_train[common_cols])\n",
        "    X_test = sanitize_cols(X_test[common_cols])\n",
        "\n",
        "    return X_train, X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdeXGibI2u2O"
      },
      "source": [
        "## 4. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-bFWrk-2u2O",
        "outputId": "25cf3268-5394-4111-c5ec-5af454c95090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing datasets...\n",
            "Engineering features...\n",
            "Converting categorical columns...\n",
            "Preprocessing complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"Preparing datasets...\")\n",
        "\n",
        "y_train_target = y_train['MathScore'].copy()\n",
        "\n",
        "# Remove leakage columns\n",
        "all_math_cols = [c for c in X_train.columns if c.startswith('math_q')]\n",
        "cols_to_ban = [c for c in all_math_cols if c != 'math_q1_total_timing'] + ['average_math_question_score', 'last_attempted_math_q']\n",
        "\n",
        "X_train_clean = X_train.drop(columns=cols_to_ban, errors='ignore').copy()\n",
        "X_test_clean = X_test.drop(columns=cols_to_ban, errors='ignore').copy()\n",
        "\n",
        "print(\"Engineering features...\")\n",
        "X_train_clean = engineer_features(X_train_clean)\n",
        "X_train_clean = engineer_psychometrics(X_train_clean)\n",
        "\n",
        "X_test_clean = engineer_features(X_test_clean)\n",
        "X_test_clean = engineer_psychometrics(X_test_clean)\n",
        "\n",
        "print(\"Converting categorical columns...\")\n",
        "obj_cols = X_train_clean.select_dtypes(include='object').columns\n",
        "for col in obj_cols:\n",
        "    X_train_clean[col] = X_train_clean[col].astype('category')\n",
        "    if col in X_test_clean.columns:\n",
        "        X_test_clean[col] = X_test_clean[col].astype('category')\n",
        "\n",
        "X_train_clean['student_persona'] = X_train_clean['student_persona'].astype('category')\n",
        "X_test_clean['student_persona'] = X_test_clean['student_persona'].astype('category')\n",
        "\n",
        "print(\"Preprocessing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d22190ae"
      },
      "source": [
        "## 5. Optimize Classifier Parameters\n",
        "\n",
        "Split data, train classifiers, and find optimal ensemble weights and threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed8fa492",
        "outputId": "b0535306-847d-42bc-b7ee-7ad34c17d9d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data for optimization...\n",
            "Optimization split - Train: 937668, Val: 234418\n"
          ]
        }
      ],
      "source": [
        "print(\"Splitting data for optimization...\")\n",
        "\n",
        "y_binary_split = (y_train_target > 0).astype(int)\n",
        "X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(\n",
        "    X_train_clean, y_train_target, test_size=0.2, random_state=42, stratify=y_binary_split\n",
        ")\n",
        "\n",
        "print(f\"Optimization split - Train: {X_train_opt.shape[0]}, Val: {X_val_opt.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5b6bb2d",
        "outputId": "9b5ed702-24fd-490a-af62-87136cf9240b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting validation predictions for optimization...\n",
            "\n",
            "Processing year 2015 for optimization...\n",
            "\n",
            "Processing year 2018 for optimization...\n",
            "\n",
            "Processing year 2022 for optimization...\n",
            "Total validation samples: 234418\n"
          ]
        }
      ],
      "source": [
        "print(\"Collecting validation predictions for optimization...\")\n",
        "\n",
        "all_y_binary_val = []\n",
        "all_prob_lgb_val = []\n",
        "all_prob_xgb_val = []\n",
        "\n",
        "years = [2015, 2018, 2022]\n",
        "\n",
        "for year in years:\n",
        "    print(f\"\\nProcessing year {year} for optimization...\")\n",
        "\n",
        "    train_mask = X_train_opt['Year'] == year\n",
        "    val_mask = X_val_opt['Year'] == year\n",
        "\n",
        "    if not val_mask.any():\n",
        "        continue\n",
        "\n",
        "    X_curr_train = X_train_opt[train_mask].copy()\n",
        "    y_curr_train = y_train_opt[train_mask].copy()\n",
        "    X_curr_val = X_val_opt[val_mask].copy()\n",
        "    y_curr_val = y_val_opt[val_mask].copy()\n",
        "\n",
        "    # Process data\n",
        "    X_curr_train, X_curr_val = process_year_data(X_curr_train, y_curr_train, X_curr_val)\n",
        "\n",
        "    # Train classifiers\n",
        "    y_binary_train = (y_curr_train > 0).astype(int)\n",
        "    y_binary_val = (y_curr_val > 0).astype(int)\n",
        "\n",
        "    clf_lgb = lgb.LGBMClassifier(n_estimators=400, learning_rate=0.03, random_state=42, verbose=-1)\n",
        "    clf_lgb.fit(X_curr_train, y_binary_train)\n",
        "    prob_lgb = clf_lgb.predict_proba(X_curr_val)[:, 1]\n",
        "\n",
        "    clf_xgb = xgb.XGBClassifier(n_estimators=400, learning_rate=0.03, enable_categorical=True, tree_method='hist', random_state=42)\n",
        "    clf_xgb.fit(X_curr_train, y_binary_train)\n",
        "    prob_xgb = clf_xgb.predict_proba(X_curr_val)[:, 1]\n",
        "\n",
        "    all_y_binary_val.append(y_binary_val)\n",
        "    all_prob_lgb_val.append(prob_lgb)\n",
        "    all_prob_xgb_val.append(prob_xgb)\n",
        "\n",
        "final_y_binary_val = pd.concat(all_y_binary_val)\n",
        "final_prob_lgb_val = np.concatenate(all_prob_lgb_val)\n",
        "final_prob_xgb_val = np.concatenate(all_prob_xgb_val)\n",
        "\n",
        "print(f\"Total validation samples: {len(final_y_binary_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d265c80e",
        "outputId": "119050c5-86bf-4d4a-ad79-9104bf438417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing classifier weights and threshold...\n",
            "\n",
            "Best F1-score: 0.9903\n",
            "Optimal LGBM Weight: 0.80\n",
            "Optimal Threshold: 0.46\n"
          ]
        }
      ],
      "source": [
        "print(\"Optimizing classifier weights and threshold...\")\n",
        "\n",
        "best_f1 = -1\n",
        "best_lgb_weight = 0.5\n",
        "best_threshold = 0.5\n",
        "\n",
        "for lgb_weight in np.arange(0.1, 1.0, 0.1):\n",
        "    xgb_weight = 1 - lgb_weight\n",
        "    for threshold in np.arange(0.1, 0.96, 0.01):\n",
        "        ensemble_probs = (lgb_weight * final_prob_lgb_val) + (xgb_weight * final_prob_xgb_val)\n",
        "        binary_predictions = (ensemble_probs > threshold).astype(int)\n",
        "        f1 = f1_score(final_y_binary_val, binary_predictions)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_lgb_weight = lgb_weight\n",
        "            best_threshold = threshold\n",
        "\n",
        "print(f\"\\nBest F1-score: {best_f1:.4f}\")\n",
        "print(f\"Optimal LGBM Weight: {best_lgb_weight:.2f}\")\n",
        "print(f\"Optimal Threshold: {best_threshold:.2f}\")\n",
        "\n",
        "LGB_WEIGHT_CLASSIFIER = best_lgb_weight\n",
        "BEST_THRESH = best_threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CedDN7wz2u2P"
      },
      "source": [
        "## 6. Train Final Models and Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A7k06HK2u2P",
        "outputId": "d3255cad-2dad-4099-d01a-9ffa3f9fe9fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training final models for year 2015\n",
            "==================================================\n",
            "Train: 348119, Test: 174102\n",
            "Completed year 2015\n",
            "\n",
            "==================================================\n",
            "Training final models for year 2018\n",
            "==================================================\n",
            "Train: 411320, Test: 205889\n",
            "Completed year 2018\n",
            "\n",
            "==================================================\n",
            "Training final models for year 2022\n",
            "==================================================\n",
            "Train: 412647, Test: 206053\n",
            "Completed year 2022\n"
          ]
        }
      ],
      "source": [
        "final_submission = pd.DataFrame(index=X_test_clean.index)\n",
        "final_submission['MathScore'] = 0.0\n",
        "\n",
        "for year in years:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training final models for year {year}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    train_mask = X_train_clean['Year'] == year\n",
        "    test_mask = X_test_clean['Year'] == year\n",
        "\n",
        "    if not test_mask.any():\n",
        "        continue\n",
        "\n",
        "    X_curr_train = X_train_clean[train_mask].copy()\n",
        "    y_curr_train = y_train_target[train_mask].copy()\n",
        "    X_curr_test = X_test_clean[test_mask].copy()\n",
        "\n",
        "    print(f\"Train: {len(X_curr_train)}, Test: {len(X_curr_test)}\")\n",
        "\n",
        "    # Process data\n",
        "    X_curr_train, X_curr_test = process_year_data(X_curr_train, y_curr_train, X_curr_test)\n",
        "\n",
        "    # Stage 1: Classification\n",
        "    y_binary = (y_curr_train > 0).astype(int)\n",
        "\n",
        "    clf_lgb = lgb.LGBMClassifier(n_estimators=400, learning_rate=0.03, random_state=42, verbose=-1)\n",
        "    clf_lgb.fit(X_curr_train, y_binary)\n",
        "    prob_lgb = clf_lgb.predict_proba(X_curr_test)[:, 1]\n",
        "\n",
        "    clf_xgb = xgb.XGBClassifier(n_estimators=400, learning_rate=0.03, enable_categorical=True, tree_method='hist', random_state=42)\n",
        "    clf_xgb.fit(X_curr_train, y_binary)\n",
        "    prob_xgb = clf_xgb.predict_proba(X_curr_test)[:, 1]\n",
        "\n",
        "    prob_avg = LGB_WEIGHT_CLASSIFIER * prob_lgb + (1 - LGB_WEIGHT_CLASSIFIER) * prob_xgb\n",
        "\n",
        "    # Stage 2: Regression\n",
        "    non_zero_mask = y_curr_train > 0\n",
        "    X_reg = X_curr_train[non_zero_mask]\n",
        "    y_reg = y_curr_train[non_zero_mask]\n",
        "\n",
        "    reg_lgb = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.02, num_leaves=70, min_child_samples=10, random_state=42, verbose=-1)\n",
        "    reg_lgb.fit(X_reg, y_reg)\n",
        "    pred_lgb = reg_lgb.predict(X_curr_test)\n",
        "\n",
        "    reg_xgb = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.02, max_depth=9, enable_categorical=True, tree_method='hist', random_state=42)\n",
        "    reg_xgb.fit(X_reg, y_reg)\n",
        "    pred_xgb = reg_xgb.predict(X_curr_test)\n",
        "\n",
        "    final_reg_pred = 0.2 * pred_lgb + 0.8 * pred_xgb\n",
        "    final_pred = np.where(prob_avg > BEST_THRESH, final_reg_pred, 0.0)\n",
        "\n",
        "    final_submission.loc[test_mask, 'MathScore'] = final_pred\n",
        "    print(f\"Completed year {year}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS28wBG72u2Q"
      },
      "source": [
        "## 7. Save Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao5KyoZMNeDd",
        "outputId": "545e41ae-4f09-42e6-958a-da738153c800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving submission.csv...\n",
            "Done! Submission saved.\n",
            "\n",
            "Total predictions: 586044\n",
            "Non-zero predictions: 368263\n",
            "\n",
            "Preview:\n",
            "        ID   MathScore\n",
            "0   412660  112.982534\n",
            "1   554658   76.146082\n",
            "2   937138    0.000000\n",
            "3   752986  236.625236\n",
            "4  1084508  167.005639\n",
            "5   527030   60.592353\n",
            "6   782794    0.000000\n",
            "7   169543  185.386008\n",
            "8  1697342  138.635419\n",
            "9   724544    0.000000\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSaving submission.csv...\")\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': X_test['Unnamed: 0'],\n",
        "    'MathScore': final_submission['MathScore']\n",
        "})\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Done! Submission saved.\")\n",
        "print(f\"\\nTotal predictions: {len(submission_df)}\")\n",
        "print(f\"Non-zero predictions: {(submission_df['MathScore'] > 0).sum()}\")\n",
        "print(\"\\nPreview:\")\n",
        "print(submission_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCWNyAXb2u2R"
      },
      "source": [
        "## 8. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3yVpyPYxrBz",
        "outputId": "1b61a38f-7e94-4ddf-8287-53c83fbd3982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared score: 0.78\n"
          ]
        }
      ],
      "source": [
        "y_test = pd.read_csv('/content/drive/MyDrive/Copy of y_test.csv')\n",
        "r2 = r2_score(y_test['MathScore'], final_submission['MathScore'])\n",
        "print(f\"R-squared score: {r2:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}